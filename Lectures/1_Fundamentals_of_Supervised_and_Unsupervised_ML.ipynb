{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fundamentals of Supervised and Unsupervised ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives:\n",
    "- Understand the importance of ML in mechanics and materials\n",
    "- Understand what we need to learn a model\n",
    "- Understand how to use learning curves to asses model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any ML model, it is important that we have the the **right type of data**. This means we have to ensure it is relevant and of a high-quality. We need to ensure it isn't biased in any way.\n",
    "\n",
    "The **manifold hypothesis** states that many real-world high-dimensional datasets actually lie along a low-dimensional latent manifold inside that high-dimensional space. \n",
    "\n",
    "ML algorithms can learn this low-dimensional structure of data, which is something that would be impossible for humans to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Machine Learning Algo Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Gather Data**  \n",
    "   Collect data from relevant sources.\n",
    "\n",
    "2. **Data Processing & Cleaning**  \n",
    "   Preprocess the data, handle missing values, and clean it for analysis.\n",
    "\n",
    "3. **Build the Model**  \n",
    "   Choose an appropriate machine learning algorithm and train the model on the data.\n",
    "\n",
    "4. **Extract Insights**  \n",
    "   Analyse the model's results. What does it tell us about the data?\n",
    "\n",
    "5. **Data Visualization**  \n",
    "   Visualize the findings to communicate insights effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning** is the most important and longest step in this process. Here are some important processes in cleaning a dataset.\n",
    "- *Data standardisation* -> convert data into the same format (same units, remove punctuation etc)\n",
    "- *Removing unwanted observations* -> get rid of duplicates or redundant data. Consider what is 'valid' for your model\n",
    "- *Handling missing data* -> dealing with unknown data (e.g. NaN). You may ignore them, set them to 0 or try to predict them\n",
    "- *Structural error solving* -> errors in the setup of the data (e.d. mislabelled classes)\n",
    "- *Outliers' management* -> dealing with values that don't belong in out dataset (e.g. we might solve this by defining min and max values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data in materials and mechanics applications** can be:\n",
    "- expensive to obtain\n",
    "- difficult to measure\n",
    "- noisy (if its obtained from measurements)\n",
    "- deterministic (if its simulated)\n",
    "- heterogenous (comed from different sources)\n",
    "- multi-modal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature engineering is the process of transforming raw data into features that are suitable for machine learning models**. \n",
    "\n",
    "For example, in a dataset of housing prices, features could include the number of bedrooms, square footage, the location, and the age of the property. If we have a dataset of customers, features could include age, gender and occupation.\n",
    "\n",
    "Features can be:\n",
    "- Quantitative/qualitative\n",
    "- Visible/latent\n",
    "- Deterministic/statistical\n",
    "\n",
    "Why do we do feature engineering?\n",
    "1) To reduce the complexity of the data\n",
    "2) To identify relevant features or design meaningful transformations (requires domain expertise)\n",
    "\n",
    "Typucally, in deep learning architectures, features are automatically extracted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative features will can have varying magnitudes. Feature scaling is the process of normalising the range of features in your dataset. This meanse that no feature dominates or skews the model too much.\n",
    "\n",
    "CONTINUE FROM HERE\n",
    "PG 24 L1 NOTES \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
